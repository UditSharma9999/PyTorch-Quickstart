{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6065dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a008cc4",
   "metadata": {},
   "source": [
    "# Download training and testing data from open datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c07f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015d089adf1646c780c34d005d7f0422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada12c199eb545af8f21a61f5f384bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e3df9d1101459b8dcdfae62e2b7d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d974de27cd914968965190f6f6e2412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa7a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b0c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc82b3",
   "metadata": {},
   "source": [
    "# Create data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52eed7",
   "metadata": {},
   "source": [
    "- We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242783e4",
   "metadata": {},
   "source": [
    "- root is the path where the train/test data is stored,\n",
    "- train specifies training or test dataset,\n",
    "- download=True downloads the data from the internet if it’s not available at root.\n",
    "- transform and target_transform specify the feature and label transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436998a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2255c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af02d41",
   "metadata": {},
   "source": [
    "# Creating a Custom Dataset for your files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0676ba34",
   "metadata": {},
   "source": [
    "A custom Dataset class must implement three functions: __init__, __len__, and __getitem__. Take a look at this implementation; the FashionMNIST images are stored in a directory img_dir, and their labels are stored separately in a CSV file annotations_file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5537b3a4",
   "metadata": {},
   "source": [
    "1. The __init__ function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms (covered in more detail in the next section).\n",
    "2. The __len__ function returns the number of samples in our dataset.\n",
    "\n",
    "3. The __getitem__ function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the image’s location on disk, converts that to a tensor using read_image, retrieves the corresponding label from the csv data in self.img_labels, calls the transform functions on them (if applicable), and returns the tensor image and corresponding label in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad86e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9d3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c6464",
   "metadata": {},
   "source": [
    "DataLoader is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ade771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3768a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "714ea3d3",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ed399",
   "metadata": {},
   "source": [
    "for more headover to https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825e680",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef393de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.flatten(inputs)\n",
    "        logits = self.linear_relu_stack(inputs)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922bd038",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56b67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300df521",
   "metadata": {},
   "source": [
    "- In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1f70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae21094",
   "metadata": {},
   "source": [
    "- We also check the model’s performance against the test dataset to ensure it is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d70afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d242f9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.292328  [    0/60000]\n",
      "loss: 2.282763  [ 6400/60000]\n",
      "loss: 2.258832  [12800/60000]\n",
      "loss: 2.260273  [19200/60000]\n",
      "loss: 2.234834  [25600/60000]\n",
      "loss: 2.218493  [32000/60000]\n",
      "loss: 2.231970  [38400/60000]\n",
      "loss: 2.196277  [44800/60000]\n",
      "loss: 2.192450  [51200/60000]\n",
      "loss: 2.162089  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 2.148287 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.157157  [    0/60000]\n",
      "loss: 2.148180  [ 6400/60000]\n",
      "loss: 2.080082  [12800/60000]\n",
      "loss: 2.102502  [19200/60000]\n",
      "loss: 2.044580  [25600/60000]\n",
      "loss: 1.998074  [32000/60000]\n",
      "loss: 2.032519  [38400/60000]\n",
      "loss: 1.947499  [44800/60000]\n",
      "loss: 1.954966  [51200/60000]\n",
      "loss: 1.888997  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 1.868629 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.903441  [    0/60000]\n",
      "loss: 1.872151  [ 6400/60000]\n",
      "loss: 1.740409  [12800/60000]\n",
      "loss: 1.787354  [19200/60000]\n",
      "loss: 1.670048  [25600/60000]\n",
      "loss: 1.639128  [32000/60000]\n",
      "loss: 1.666594  [38400/60000]\n",
      "loss: 1.563384  [44800/60000]\n",
      "loss: 1.592137  [51200/60000]\n",
      "loss: 1.491599  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.492435 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.565285  [    0/60000]\n",
      "loss: 1.528488  [ 6400/60000]\n",
      "loss: 1.369961  [12800/60000]\n",
      "loss: 1.443142  [19200/60000]\n",
      "loss: 1.321113  [25600/60000]\n",
      "loss: 1.337766  [32000/60000]\n",
      "loss: 1.352543  [38400/60000]\n",
      "loss: 1.277886  [44800/60000]\n",
      "loss: 1.318347  [51200/60000]\n",
      "loss: 1.221146  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.235446 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.318704  [    0/60000]\n",
      "loss: 1.299543  [ 6400/60000]\n",
      "loss: 1.128775  [12800/60000]\n",
      "loss: 1.232429  [19200/60000]\n",
      "loss: 1.105154  [25600/60000]\n",
      "loss: 1.149555  [32000/60000]\n",
      "loss: 1.169847  [38400/60000]\n",
      "loss: 1.107069  [44800/60000]\n",
      "loss: 1.151906  [51200/60000]\n",
      "loss: 1.071824  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.080588 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f15c6",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d41f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ebd4d",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969d1dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9847cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
